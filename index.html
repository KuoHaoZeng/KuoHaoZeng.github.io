<!DOCTYPE html>
<html lang="en-us">

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Your description">
  <meta name="author" content="Kuo-Hao Zeng">
  <meta name="generator" content="Hugo 0.31.1" />
  <title>Kuo-Hao Zeng</title>
  <!-- Stylesheets -->
  <link href="css/bootstrap-v3.3.7/bootstrap.min.css" rel="stylesheet">
  <link href="css/agency.css" rel="stylesheet">
  <link href="css/jquery.form-validator-v2.3.44/theme-default.min.css" rel="stylesheet">

  

  <!-- Custom Fonts -->
  <link href="font-awesome-v4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

  
    <link href="//fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Kaushan+Script" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700" rel="stylesheet" type="text/css">
  

  
    <link rel="shortcut icon" type="image/x-icon" href="uw.ico">
    <link rel="icon" type="image/x-icon" href="uw.ico">
  

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
  <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
  <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>


  <body id="page-top" class="index">
    
      <!-- AboutMe -->
<section id="aboutme">
  <div class="container">
    <div class="row">
      <div class="col-xs-1 vcenter">
      </div>
      <div class="col-xs-3 vcenter">
        <div class="aboutme-img">
          <img src="img/aboutme/hao.jpg" class="img-responsive img-rounded" style="float: right; border-radius: 60%;">
        </div>
      </div>
      <div class="col-xs-6 text-center">
        <br/>
        <h2 class="section-heading">Kuo-Hao Zeng 曾國豪</h2>
        <h3 class="aboutme-info">Research Scientist, Allen Institute for AI (Ai2)</h3>
        <h3 class="aboutme-info2">khzeng <em>at</em> allenai.org</h3>
        <ul class="list-inline social-buttons">
          
            <li><a href="https://scholar.google.com/citations?user=SRWelkkAAAAJ"><i class="fa fa-graduation-cap"></i></a></li>

            <li><a href="https://twitter.com/KuoHaoZeng"><i class="fa fa-twitter"></i></a></li>

        </ul>
      </div>
    </div>
<!-- ...
      <h3 class="aboutme-news"><font color=red><strong>News:</strong></font><br/><ul>
<li>I will join UW CSE as a Ph.D. student in September 2018.</li>
</ul>
</h3>
-->
    <div class="row">
      <div class="col-xs-12 vcenter">
        <h3 class="aboutme-subheading">I am a research scientist at the <a href=https://allenai.org>Allen Institute for AI (Ai2)</a>. My current research interests are in large-scale policy training for embodied agents, leveraging the capabilities of foundational vision models and multimodal language models.<br/><br/>I received my Ph.D. in the <a href=https://www.cs.washington.edu>Computer Science & Engineering</a> from the <a href=https://www.washington.edu>University of Washington</a>, advised by <a href=https://homes.cs.washington.edu/~ali/>Ali Farhadi</a> and <a href=http://roozbehm.info>Roozbeh Mottaghi</a> in <a href=https://raivn.cs.washington.edu>RAIVN Lab</a>.<br/><br/> My <a href=assets/CV.pdf>CV [PDF]</a>, last updated Oct 2024.</h3>
      </div>
    </div>
</section>
    
      <!-- Publications -->
<section id="publications">
  <div class="container">
    <div class="row">
      <div class="col-xs-12 text">
          <h2 class="section-subheading">Selected Publications</h2>
          <h4><span style="font-weight: 200;">* equal contribution; † equal advising</span></h4>
      </div>
    </div>
    </br>

      <div class="row">
          <div class="publications-list">
              <div class="col-xs-4 vcenter flexbox">

                  <img src="img/publications/Molmo.png" class="img-rounded img-responsive" alt="">

              </div>
              <div class="col-xs-8 vcenter">
                  <h3>Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Multimodal Models</h3>
                  <h4>Matt Deitke*, Christopher Clark*, Sangho Lee, Rohun Tripathi, Yue Yang, Jae Sung Park, Mohammadreza Salehi, Niklas Muennighoff, Kyle Lo, Luca Soldaini, Jiasen Lu, Taira Anderson, Erin Bransom, Kiana Ehsani, Huong Ngo, YenSung Chen, Ajay Patel, Mark Yatskar, Chris Callison-Burch, Andrew Head, Rose Hendrix, Favyen Bastani, Eli VanderBilt, Nathan Lambert, Yvonne Chou, Arnavi Chheda, Jenna Sparks, Sam Skjonsberg, Michael Schmitz, Aaron Sarnat, Byron Bischoff, Pete Walsh, Chris Newell, Piper Wolters, Tanmay Gupta, <span style="font-weight: 600;">Kuo-Hao Zeng</span>, Jon Borchardt, Dirk Groeneveld, Jen Dumas, Crystal Nam, Sophie Lebrecht, Caitlin Wittlif, Carissa Schoenick, Oscar Michel, Ranjay Krishna, Luca Weihs, Noah A Smith, Hannaneh Hajishirzi, Ross Girshick, Ali Farhadi, Aniruddha Kembhavi</h4>
                  <h4><span style="font-weight: 600;">arXiv 2024</span></h4>
                  <ul class="list-inline">

                      <li><a href="https://www.arxiv.org/pdf/2409.17146" class="btn btn-primary btn-xs active">arXiv</a></li>
                      <li><a href="https://molmo.allenai.org/blog" class="btn btn-primary btn-xs active">blog</a></li>
                      <li><a href="https://molmo.allenai.org" class="btn btn-primary btn-xs active">demo</a></li>

                  </ul>
              </div>
          </div>
      </div>

    <div class="row">
      <div class="publications-list">
        <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/Flare.png" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>FLaRe: Achieving Masterful and Adaptive Robot Policies with Large-Scale Reinforcement Learning Fine-Tuning</h3>
            <h4>Jiaheng Hu, Rose Hendrix, Ali Farhadi, Aniruddha Kembhavi, Roberto Martín-Martín, Peter Stone, <span style="font-weight: 600;">Kuo-Hao Zeng</span>†, Kiana Ehsani†</h4>
            <h4><span style="font-weight: 600;">arXiv 2024</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/pdf/2409.16578" class="btn btn-primary btn-xs active">arXiv</a></li>
                <li><a href="https://robot-flare.github.io" class="btn btn-primary btn-xs active">project page</a></li>

            </ul>
          </div>
        </div>
      </div>

    <div class="row">
      <div class="publications-list">
        <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/Poliformer.png" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>PoliFormer: Scaling On-Policy RL with Transformers Results in Masterful Navigators</h3>
            <h4><span style="font-weight: 600;">Kuo-Hao Zeng</span>, Zichen Zhang, Kiana Ehsani, Rose Hendrix, Jordi Salvador, Alvaro Herrasti, Ross Girshick, Aniruddha Kembhavi, Luca Weihs</h4>
            <h4><span style="font-weight: 600;">CoRL 2024 Oral Presentation</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/pdf/2406.20083.pdf" class="btn btn-primary btn-xs active">arXiv</a></li>
                <li><a href="https://poliformer.allen.ai" class="btn btn-primary btn-xs active">project page</a></li>

            </ul>
          </div>
        </div>
      </div>

    <div class="row">
      <div class="publications-list">
        <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/spoc.svg" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Imitating Shortest Paths in Simulation Enables Effective Navigation and Manipulation in the Real World</h3>
            <h4>Kiana Ehsani*, Tanmay Gupta*, Rose Hendrix*, Jordi Salvador*, Luca Weihs*, <span style="font-weight: 600;">Kuo-Hao Zeng</span>*, Kunal Pratap Singh, Yejin Kim, Winson Han, Alvaro Herrasti, Ranjay Krishna, Dustin Schwenk, Eli VanderBilt, Aniruddha Kembhavi</h4>
            <h4><span style="font-weight: 600;">CVPR 2024</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/pdf/2312.02976.pdf" class="btn btn-primary btn-xs active">arXiv</a></li>
                <li><a href="https://spoc-robot.github.io" class="btn btn-primary btn-xs active">project page</a></li>
                <li><a href="https://github.com/allenai/spoc-robot-training" class="btn btn-primary btn-xs active">code</a></li>

            </ul>
          </div>
        </div>
      </div>

    <div class="row">
      <div class="publications-list">
        <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/SemanticPlacement.svg" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Seeing the Unseen: Visual Common Sense for Semantic Placement</h3>
            <h4>Ram Ramrakhya, Aniruddha Kembhavi, Dhruv Batra, Zsolt Kira, <span style="font-weight: 600;">Kuo-Hao Zeng</span>†, Luca Weihs†</h4>
            <h4><span style="font-weight: 600;">CVPR 2024</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/pdf/2401.07770.pdf" class="btn btn-primary btn-xs active">arXiv</a></li>
                <li><a href="https://ram81.github.io/projects/seeing-unseen.html" class="btn btn-primary btn-xs active">project page</a></li>
                <li><a href="https://github.com/Ram81/seeing-unseen" class="btn btn-primary btn-xs active">code</a></li>

            </ul>
          </div>
        </div>
      </div>

    <div class="row">
      <div class="publications-list">
        <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/EmbodiedCodebokLogo.svg" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Selective Visual Representations Improve Convergence and Generalization for Embodied AI</h3>
            <h4>Ainaz Eftekhar*, <span style="font-weight: 600;">Kuo-Hao Zeng</span>*, Jiafei Duan, Ali Farhadi, Ani Kembhavi, Ranjay Krishna</h4>
            <h4><span style="font-weight: 600;">ICLR 2024 Spotlight</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/pdf/2311.04193.pdf" class="btn btn-primary btn-xs active">arXiv</a></li>
                <li><a href="https://embodied-codebook.github.io" class="btn btn-primary btn-xs active">project page</a></li>
                <li><a href="https://github.com/allenai/procthor-rl" class="btn btn-primary btn-xs active">code</a></li>

            </ul>
          </div>
        </div>
      </div>

    <div class="row">
      <div class="publications-list">
        <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/AAP.gif" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Moving Forward by Moving Backward: Embedding Action Impact over Action Semantics</h3>
            <h4><span style="font-weight: 600;">Kuo-Hao Zeng</span>, Luca Weihs, Roozbeh Mottaghi, Ali Farhadi</h4>
            <h4><span style="font-weight: 600;">ICLR 2023 Oral Presentation</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/abs/2304.12289" class="btn btn-primary btn-xs active">arXiv</a></li>
                <li><a href="https://prior.allenai.org/projects/action-adaptive-policy" class="btn btn-primary btn-xs active">project page</a></li>
                <li><a href="https://github.com/KuoHaoZeng/AAP" class="btn btn-primary btn-xs active">code</a></li>
                <li><a href="https://youtu.be/KHsfoZ7Yvpk" class="btn btn-primary btn-xs active">video</a></li>

            </ul>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="publications-list">
          <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/NIE.gif" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Pushing it out of the Way: Interactive Visual Navigation</h3>
            <h4><span style="font-weight: 600;">Kuo-Hao Zeng</span>, Luca Weihs, Ali Farhadi, Roozbeh Mottaghi</h4>
            <h4><span style="font-weight: 600;">CVPR 2021</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/abs/2104.14040" class="btn btn-primary btn-xs active">arXiv</a></li>
                <li><a href="https://prior.allenai.org/projects/interactive-visual-navigation" class="btn btn-primary btn-xs active">project page</a></li>
                <li><a href="https://github.com/KuoHaoZeng/Interactive_Visual_Navigation" class="btn btn-primary btn-xs active">code</a></li>
                <li><a href="https://youtu.be/q8xqxgnLEY4" class="btn btn-primary btn-xs active">video</a></li>

            </ul>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="publications-list">
          <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/allenact.jpg" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>AllenAct: A Framework for Embodied AI Research </h3>
            <h4>Luca Weihs, Jordi Salvador, Klemen Kotar, Unnat Jain, <span style="font-weight: 600;">Kuo-Hao Zeng</span>, Roozbeh Mottaghi, Aniruddha Kembhavi</h4>
            <h4><span style="font-weight: 600;">arXiv 2020</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/abs/2008.12760" class="btn btn-primary btn-xs active">arXiv</a></li>

                <li><a href="https://allenact.org" class="btn btn-primary btn-xs active">project page</a></li>

                <li><a href="https://github.com/allenai/allenact" class="btn btn-primary btn-xs active">code</a></li>
              
            </ul>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="publications-list">
          <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/DroneCatch.gif" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Visual Reaction: Learning to Play Catch with Your Drone</h3>
            <h4><span style="font-weight: 600;">Kuo-Hao Zeng</span>, Roozbeh Mottaghi, Luca Weihs, Ali Farhadi</h4>
            <h4><span style="font-weight: 600;">CVPR 2020</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/abs/1912.02155" class="btn btn-primary btn-xs active">arXiv</a></li>

                <li><a href="https://prior.allenai.org/projects/visual-reaction" class="btn btn-primary btn-xs active">project page</a></li>

                <li><a href="https://github.com/KuoHaoZeng/Visual_Reaction" class="btn btn-primary btn-xs active">code</a></li>
              
                <li><a href="https://youtu.be/iyAoPuHxvYs" class="btn btn-primary btn-xs active">Video</a></li>

                <li><a href="https://venturebeat.com/2020/06/18/researchers-use-simulation-to-teach-drones-to-catch-objects/" class="btn btn-primary btn-xs active">VentureBeat Press</a></li>
              
            </ul>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="publications-list">
          <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/style_transformer.jpeg" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Style Example-Guided Text Generation using Generative Adversarial Transformers</h3>
            <h4><span style="font-weight: 600;">Kuo-Hao Zeng</span>, Mohammad Shoeybi, Ming-Yu Liu</h4>
            <h4><span style="font-weight: 600;">arXiv 2020</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/abs/2003.00674" class="btn btn-primary btn-xs active">arXiv</a></li>
            </ul>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="publications-list">
          <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/ant_imitation.gif" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Visual Forecasting by Imitating Dynamics in Natural Sequences</h3>
            <h4><span style="font-weight: 600;">Kuo-Hao Zeng</span>, William B. Shen, De-An Huang, Min Sun, Juan Carlos Niebles</h4>
            <h4><span style="font-weight: 600;">ICCV 2017 Spotlight</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/abs/1708.05827" class="btn btn-primary btn-xs active">arXiv</a></li>
              
                <li><a href="https://youtu.be/2cDnuoEbVmQ" class="btn btn-primary btn-xs active">video</a></li>
              
                <li><a href="https://www.youtube.com/watch?v=8WVKeiZikjg" class="btn btn-primary btn-xs active">talk</a></li>
              
            </ul>
          </div>
        </div>
      </div>
    
      <div class="row">
        <div class="publications-list">
          <div class="col-xs-4 vcenter flexbox">
            
            <img src="img/publications/RiskAware.gif" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Agent-Centric Risk Assessment: Accident Anticipation and Risky Region Localization</h3>
            <h4><span style="font-weight: 600;">Kuo-Hao Zeng</span>, Shih-Han Chou, Fu-Hsiang Chan, Juan Carlos Niebles, Min Sun</h4>
            <h4><span style="font-weight: 600;">CVPR 2017 Spotlight</span></h4>
            <ul class="list-inline">
              
                <li><a href="https://arxiv.org/abs/1705.06560" class="btn btn-primary btn-xs active">arXiv</a></li>
              
                <li><a href="http://aliensunmin.github.io/project/video-Forecasting/" class="btn btn-primary btn-xs active">project page</a></li>

                <li><a href="https://goo.gl/forms/WtMgvkX7AErt454V2" class="btn btn-primary btn-xs active">dataset</a></li>
              
                <li><a href="https://www.youtube.com/watch?v=CGLZhd-c0hw" class="btn btn-primary btn-xs active">video</a></li>
              
            </ul>
          </div>
        </div>
      </div>

     <div class="row">
        <div class="publications-list">
          <div class="col-xs-4 vcenter flexbox">

            <img src="img/publications/VideoQA.jpg" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Leveraging Video Descriptions to Learn Video Question Answering</h3>
            <h4><b>Kuo-Hao Zeng</b>, Tseng-Hung Chen, Ching-Yao Chuang, Yuan-Hong Liao, Juan Carlos Niebles, Min Sun</h4>
            <h4>AAAI 2017</h4>
            <ul class="list-inline">

                <li><a href="https://arxiv.org/abs/1611.04021" class="btn btn-primary btn-xs active">arXiv</a></li>

                <li><a href="http://aliensunmin.github.io/project/video-language/" class="btn btn-primary btn-xs active">project page</a></li>

                <li><a href="https://goo.gl/forms/HIKnmONqZ95kQ2cr1" class="btn btn-primary btn-xs active">dataset</a></li>

            </ul>
          </div>
        </div>
      </div>

      <div class="row">
        <div class="publications-list">
          <div class="col-xs-4 vcenter flexbox">

            <img src="img/publications/VideoTitle.gif" class="img-rounded img-responsive" alt="">
          </div>
          <div class="col-xs-8 vcenter">
            <h3>Title Generation for User Generated Videos</h3>
            <h4><b>Kuo-Hao Zeng</b>, Tseng-Hung Chen, Juan Carlos Niebles, Min Sun</h4>
            <h4>ECCV 2016</h4>
            <ul class="list-inline">

                <li><a href="https://arxiv.org/abs/1608.07068" class="btn btn-primary btn-xs active">arXiv</a></li>

                <li><a href="http://aliensunmin.github.io/project/video-language/" class="btn btn-primary btn-xs active">project page</a></li>

                <li><a href="https://goo.gl/forms/HIKnmONqZ95kQ2cr1" class="btn btn-primary btn-xs active">dataset</a></li>

                <li><a href="https://youtu.be/KCTQ0vMsyDc" class="btn btn-primary btn-xs active">video</a></li>

                <li><a href="https://www.microsoft.com/en-us/research/blog/bots-generate-video-titles-and-tags-to-bring-ai-researchers-one-step-closer-to-visual-intelligence/" class="btn btn-primary btn-xs active">MSRA blog</a></li>

            </ul>
          </div>
        </div>
      </div>
    
  </div>
</section>

    

    
    

    

    

    

    

    <!-- jQuery -->
<script src="js/jquery-v3.3.1/jquery.min.js"></script>

<!-- Bootstrap Core -->
<script src="js/bootstrap-v3.3.7/bootstrap.min.js"></script>

<!-- Form Validation -->
<script src="js/jquery.form-validator-v2.3.44/jquery.form-validator.min.js"></script>

<!-- Custom Theme -->
<script src="js/agency.js"></script>


<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-97026471-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>






  </body>
</html>
